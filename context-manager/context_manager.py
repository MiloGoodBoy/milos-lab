#!/usr/bin/env python3
"""
Context Manager - Milo's Self-Monitoring Tool

Monitors session context usage, predicts when limits will be hit,
and automatically archives sessions before compaction kicks in.

Run: python3 context_manager.py
"""

import json
import os
import glob
from datetime import datetime, timedelta
from pathlib import Path

# Configuration
WORKSPACE = "/home/ubuntu/.openclaw/workspace"
SESSIONS_DIR = "/home/ubuntu/.openclaw/sessions"
ARCHIVE_DIR = "/home/ubuntu/.openclaw/archive"
MEMORY_DIR = "/home/ubuntu/.openclaw/memory"

# Thresholds
CONTEXT_WARNING_PCT = 75  # Warn when at 75%
CONTEXT_CRITICAL_PCT = 85  # Force archive at 85%
MAX_SESSION_SIZE_KB = 50  # Max session size before archival

class ContextManager:
    def __init__(self):
        self.warnings = []
        self.archives = []
        
    def get_session_files(self):
        """Find all session files."""
        sessions = []
        # Check workspace sessions.json
        workspace_sessions = Path(WORKSPACE) / "sessions.json"
        if workspace_sessions.exists():
            size_kb = workspace_sessions.stat().st_size / 1024
            sessions.append({
                "path": str(workspace_sessions),
                "size_kb": size_kb,
                "type": "workspace"
            })
        
        # Check sessions dir
        if Path(SESSIONS_DIR).exists():
            for f in Path(SESSIONS_DIR).glob("*.json"):
                size_kb = f.stat().st_size / 1024
                sessions.append({
                    "path": str(f),
                    "size_kb": size_kb,
                    "type": "session"
                })
        
        return sessions
    
    def analyze_session(self, session_path):
        """Analyze a single session file."""
        try:
            with open(session_path, 'r') as f:
                data = json.load(f)
            
            # Count messages
            messages = data.get("messages", [])
            
            # Estimate token count (rough: ~4 chars per token)
            total_chars = sum(len(str(m.get("content", ""))) for m in messages)
            estimated_tokens = total_chars / 4
            
            return {
                "message_count": len(messages),
                "estimated_tokens": int(estimated_tokens),
                "total_chars": total_chars,
                "last_modified": datetime.fromtimestamp(
                    os.path.getmtime(session_path)
                ).isoformat() if os.path.exists(session_path) else None
            }
        except Exception as e:
            return {"error": str(e)}
    
    def should_archive(self, size_kb):
        """Determine if session should be archived."""
        return size_kb > MAX_SESSION_SIZE_KB
    
    def archive_session(self, session_info):
        """Archive a session file."""
        os.makedirs(ARCHIVE_DIR, exist_ok=True)
        
        src = session_info["path"]
        filename = Path(src).name
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dst = Path(ARCHIVE_DIR) / f"{timestamp}_{filename}"
        
        # Create handoff note
        analysis = self.analyze_session(src)
        handoff_note = self.generate_handoff_note(session_info, analysis)
        
        # Save handoff note
        note_path = Path(ARCHIVE_DIR) / f"{timestamp}_handoff.md"
        with open(note_path, 'w') as f:
            f.write(handoff_note)
        
        # Move session
        os.rename(src, dst)
        
        self.archives.append({
            "source": src,
            "destination": str(dst),
            "handoff": str(note_path)
        })
        
        return handoff_note
    
    def generate_handoff_note(self, session_info, analysis):
        """Generate a handoff note for archived session."""
        return f"""# Session Handoff Note

**Archived:** {datetime.now().isoformat()}
**Source:** {session_info['path']}
**Size:** {session_info['size_kb']:.1f} KB

## Session Analysis

- **Messages:** {analysis.get('message_count', 'N/A')}
- **Est. Tokens:** {analysis.get('estimated_tokens', 'N/A')}
- **Last Modified:** {analysis.get('last_modified', 'N/A')}

## Status

‚ö†Ô∏è Session archived due to size limits. Fresh session should load only essential memory files.

---
*Generated by Milo's Context Manager*
"""
    
    def check_memory_health(self):
        """Check memory file sizes and health."""
        memory_files = []
        
        for pattern in ["MEMORY.md", "memory/*.md"]:
            memory_files.extend(glob.glob(f"{WORKSPACE}/{pattern}"))
        
        issues = []
        for mf in memory_files:
            size_kb = Path(mf).stat().st_size / 1024
            if size_kb > 100:  # Memory file > 100KB is concerning
                issues.append({
                    "file": mf,
                    "size_kb": size_kb,
                    "issue": "Large memory file may impact context"
                })
        
        return {
            "memory_files": len(memory_files),
            "issues": issues
        }
    
    def run(self):
        """Main execution."""
        print("=" * 50)
        print("Milo's Context Manager")
        print(f"Run: {datetime.now().isoformat()}")
        print("=" * 50)
        
        # Check sessions
        sessions = self.get_session_files()
        print(f"\nüìä Found {len(sessions)} session file(s)")
        
        for s in sessions:
            print(f"  - {s['path']}: {s['size_kb']:.1f} KB ({s['type']})")
            
            # Check if should warn
            pct = (s['size_kb'] / MAX_SESSION_SIZE_KB) * 100
            if pct >= CONTEXT_CRITICAL_PCT:
                self.warnings.append(f"üî¥ CRITICAL: {s['path']} at {pct:.0f}% - archiving required")
                handoff = self.archive_session(s)
                print(f"    ‚Üí Archived with handoff note")
            elif pct >= CONTEXT_WARNING_PCT:
                self.warnings.append(f"üü° WARNING: {s['path']} at {pct:.0f}% - consider archiving")
                print(f"    ‚Üí Warning issued")
        
        # Check memory health
        print("\nüß† Memory Health:")
        mem_health = self.check_memory_health()
        print(f"  - Memory files: {mem_health['memory_files']}")
        for issue in mem_health['issues']:
            print(f"  - ‚ö†Ô∏è {issue['file']}: {issue['size_kb']:.1f} KB - {issue['issue']}")
        
        # Summary
        print("\n" + "=" * 50)
        if self.warnings:
            print("‚ö†Ô∏è WARNINGS:")
            for w in self.warnings:
                print(f"  {w}")
        
        if self.archives:
            print(f"\nüì¶ ARCHIVED: {len(self.archives)} session(s)")
            for a in self.archives:
                print(f"  - {a['destination']}")
        
        if not self.warnings and not self.archives:
            print("‚úÖ All clear! Context healthy.")
        
        print("=" * 50)
        
        # Return status for cron reporting
        return {
            "warnings": self.warnings,
            "archives": self.archives,
            "session_count": len(sessions)
        }

if __name__ == "__main__":
    cm = ContextManager()
    result = cm.run()
    
    # Exit code based on status
    exit(0 if not result['warnings'] else 1)
